{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4e5f4998-9ea4-4a28-af7a-a69ceda4b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0c7ec948-831f-4166-aadc-45aaa92e4622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "# Get the data and labels\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "# Convert the labels to integers\n",
    "y = y.astype(np.int8)\n",
    "# Normalize the data (pixel values between 0 and 1)\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1748c79c-8e04-4fe2-a5fa-0d086b2e8c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (784, 60000)\n",
      "Training labels shape: (60000,)\n",
      "Testing data shape: (784, 10000)\n",
      "Testing labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = np.array(X[:60000]).T, np.array(X[60000:]).T\n",
    "y_train, y_test = np.array(y[:60000]), np.array(y[60000:])\n",
    "\n",
    "n,m=X_train.shape\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "print(f\"Testing labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8ff81c18-f998-4478-8355-5e04f5cf29cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    # He initialization for ReLU\n",
    "    w1 = np.random.randn(16, 784) * np.sqrt(2. / 784)\n",
    "    b1 = np.zeros((16, 1))\n",
    "    w2 = np.random.randn(16, 16) * np.sqrt(2. / 16)\n",
    "    b2 = np.zeros((16, 1))\n",
    "    w3 = np.random.randn(10, 16) * np.sqrt(2. / 16)\n",
    "    b3 = np.zeros((10, 1))\n",
    "    return w1, b1, w2, b2, w3, b3\n",
    "\n",
    "def load_params():\n",
    "    try:\n",
    "        with open('mnist_trained_params.pkl', 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "            w1, b1 = params['w1'], params['b1']\n",
    "            w2, b2 = params['w2'], params['b2']\n",
    "            w3, b3 = params['w3'], params['b3']\n",
    "            print(\"Parameters loaded from mnist_trained_params.pkl\")\n",
    "    except:\n",
    "        print(\"mnist_trained_params.pkl not found. Initializing new parameters.\")\n",
    "        w1, b1, w2, b2, w3, b3 = init_params()\n",
    "    return w1, b1, w2, b2, w3, b3\n",
    "\n",
    "def ReLu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def d_ReLu(x):\n",
    "    return x>0\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def softmax(Z):\n",
    "    Z -= np.max(Z, axis=0)  # Subtract max value for numerical stability\n",
    "    A = np.exp(Z) / np.sum(np.exp(Z), axis=0)\n",
    "    return A\n",
    "\n",
    "def get_predictions(A):\n",
    "    return np.argmax(A, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8810916f-47ee-475d-bd13-f2b22a1daa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(w1,b1,w2,b2,w3,b3,x):\n",
    "    z1 = w1.dot(x) + b1\n",
    "    a1 = ReLu(z1)\n",
    "    z2 = w2.dot(a1) + b2\n",
    "    a2 = ReLu(z2)\n",
    "    z3 = w3.dot(a2) + b3\n",
    "    a3 = softmax(z3)\n",
    "    return z1, a1, z2, a2, z3, a3\n",
    "\n",
    "def update_params(w1, b1, w2, b2, w3, b3, dw1, db1, dw2, db2, dw3, db3, alpha):\n",
    "    w1 = w1 - alpha * dw1\n",
    "    b1 = b1 - alpha * db1    \n",
    "    w2 = w2 - alpha * dw2  \n",
    "    b2 = b2 - alpha * db2\n",
    "    w3 = w3 - alpha * dw3  \n",
    "    b3 = b3 - alpha * db3\n",
    "    return w1, b1, w2, b2, w3, b3\n",
    "\n",
    "def backpropagation(z1, a1, z2, a2, z3, a3, w1, w2, w3, x, y):\n",
    "    # Output layer gradients\n",
    "    dL_z3 = a3 - y\n",
    "    dL_w3 = 1/m * dL_z3.dot(a2.T)\n",
    "    dL_b3 = 1/m * np.sum(dL_z3, axis=1, keepdims=True)\n",
    "\n",
    "    # 2nd hidden layer gradients\n",
    "    dL_z2 = w3.T.dot(dL_z3) * d_ReLu(z2)\n",
    "    dL_w2 = 1/m * dL_z2.dot(a1.T)\n",
    "    dL_b2 = 1/m * np.sum(dL_z2, axis=1, keepdims=True)\n",
    "\n",
    "    # 1st hidden layer gradients\n",
    "    dL_z1 = w2.T.dot(dL_z2) * d_ReLu(z1)\n",
    "    dL_w1 = 1/m * dL_z1.dot(x.T)\n",
    "    dL_b1 = 1/m * np.sum(dL_z1, axis=1, keepdims=True)\n",
    "\n",
    "    return dL_w1, dL_b1, dL_w2, dL_b2, dL_w3, dL_b3 \n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    OHY = one_hot(Y)\n",
    "    w1, b1, w2, b2, w3, b3 = load_params()\n",
    "    for i in range(iterations):\n",
    "        z1, a1, z2, a2, z3, a3 = forward(w1, b1, w2, b2, w3, b3, X)\n",
    "        dw1, db1, dw2, db2, dw3, db3 = backpropagation(z1, a1, z2, a2, z3, a3, w1, w2, w3, X, OHY)\n",
    "        w1, b1, w2, b2, w3, b3 = update_params(w1, b1, w2, b2, w3, b3, dw1, db1, dw2, db2, dw3, db3, alpha)\n",
    "        if i % 100 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(a3)\n",
    "            print(\"Accuracy: \", get_accuracy(predictions, Y))\n",
    "    return w1, b1, w2, b2, w3, b3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e50b61f8-be2d-459e-8ff2-5b3a9108320d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters loaded from mnist_trained_params.pkl\n",
      "Iteration:  0\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Accuracy:  0.9695833333333334\n",
      "Iteration:  100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Accuracy:  0.9696166666666667\n",
      "Iteration:  200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Accuracy:  0.9696166666666667\n",
      "Iteration:  300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Accuracy:  0.9696166666666667\n",
      "Iteration:  400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Accuracy:  0.9696166666666667\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2, w3, b3 = gradient_descent(X_train, y_train, 0.001, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f7911a-f948-472a-b85b-f37d4fa94bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c01349-4022-42cd-a4d2-2a08b7128e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
